{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# AWS SageMaker PySpark Titanic Classification Model\n", "This notebook demonstrates how to:\n", "- Load the Titanic dataset from S3\n", "- Preprocess the data using PySpark\n", "- Train a Logistic Regression model\n", "- Save the trained model to S3\n", "- Load the model from S3 and perform manual predictions\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install dependencies (if not installed)\n", "!pip install pyspark"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Import Required Libraries\n", "import boto3\n", "import pyspark\n", "from pyspark.sql import SparkSession\n", "from pyspark.sql.functions import col, when\n", "from pyspark.ml.feature import StringIndexer, VectorAssembler\n", "from pyspark.ml.classification import LogisticRegression\n", "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n", "from pyspark.ml.pipeline import Pipeline"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Initialize Spark Session\n", "spark = SparkSession.builder \\\n", "    .appName(\"Titanic_Classification\") \\\n", "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n", "    .getOrCreate()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load Titanic Dataset from S3\n", "s3_bucket = \"your-s3-bucket-name\"\n", "s3_path = f\"s3a://{s3_bucket}/titanic.csv\"\n", "\n", "df = spark.read.csv(s3_path, header=True, inferSchema=True)\n", "df.show(5)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Data Preprocessing\n", "df = df.select(\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\")\n", "df = df.withColumn(\"Sex\", when(col(\"Sex\") == \"male\", 1).otherwise(0))\n", "df = df.fillna({\"Age\": df.selectExpr(\"avg(Age)\").collect()[0][0]})\n", "\n", "label_indexer = StringIndexer(inputCol=\"Survived\", outputCol=\"label\")\n", "feature_assembler = VectorAssembler(\n", "    inputCols=[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"],\n", "    outputCol=\"features\"\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train the Model\n", "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n", "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n", "pipeline = Pipeline(stages=[label_indexer, feature_assembler, lr])\n", "model = pipeline.fit(train_df)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save Model to S3\n", "s3_output_path = f\"s3a://{s3_bucket}/titanic_model\"\n", "model.write().overwrite().save(s3_output_path)\n", "print(f\"Model saved to {s3_output_path}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load Model from S3 and Perform Predictions\n", "from pyspark.ml.classification import LogisticRegressionModel\n", "\n", "model = LogisticRegressionModel.load(s3_output_path)\n", "\n", "manual_data = spark.createDataFrame([\n", "    (3, 1, 22.0, 1, 0, 7.25),\n", "    (1, 0, 38.0, 1, 0, 71.28)\n", "], [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"])\n", "\n", "manual_data = feature_assembler.transform(manual_data)\n", "manual_predictions = model.transform(manual_data)\n", "manual_predictions.select(\"features\", \"prediction\").show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 4}